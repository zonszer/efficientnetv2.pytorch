{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于转化图像类型和通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "img_path = \"data//train//Image1_1.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img_array = numpy.array(img_RGB)\n",
    "\n",
    "print(img_array.shape) \n",
    "writer.add_image(\"test\", img_array, 3, dataformats='HWC')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于creat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from dataset_define import *\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #1. create my dataset\n",
    "    transform = transforms.Compose([transforms.ToTensor()])        #opt:transforms.Grayscale(num_output_channels=1)，  transforms.resize(32)\n",
    "    root_dir = \"data\"\n",
    "    dataset_type = \"train\"\n",
    "    label = \"RGB\"\n",
    "    RGB_dataset = MyData(root_dir, label, dataset_type, transform)\n",
    "    \n",
    "    # #output---->注意data的输出格式应为[batch_size,C,H,W]\n",
    "    # train_loader = DataLoader(RGB_dataset, batch_size = 16)      \n",
    "    # writer = SummaryWriter(\"attempt_1_logs\")\n",
    "    # step = 0\n",
    "    # for data in train_loader:\n",
    "    #     writer.add_images('RGBs', data, step)         #data.Size([6, 211, 3, 32, 32])\n",
    "    #     step = step + 1\n",
    "    # writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将整数标签转为one-hot编码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from dataset_define import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_num = 211\n",
    "tensor = torch.tensor(range(patch_num))\n",
    "\n",
    "N = tensor.size(0)\n",
    "num_classes = patch_num\n",
    "one_hot = torch.zeros(N, num_classes).long()\n",
    "a = one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1104b070cf749f8b1d8e90ee596b9a0d7b90cb91fc8ec12647f48ba9555d6193"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
